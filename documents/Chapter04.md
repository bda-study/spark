# Chapter 4 구조적 API 개요 (112~, 12)


Dataset

DataFrame

SQL 테이블

SQL 뷰 (임시 테이블)

- 배치, 스트리밍 처리에서 구조적 API 사용 가능

- Dataset, DataFrame : 로우와 컬럼을 가지는 분산 테이블 형태의 컬렉션

- 비교

. DataFrame : 비타입형 (런타임시 타입 체크, Row 사용)

. Dataset : 타입형 (컴파일시 타입 체크, JavaBean/CaseClass 사용)

- 스키마 : DataFrame의 컬럼명과 데이터 타입을 정의

* 스키마 온 리드 : 데이터소스에서 스키마 정보를 획득

- 스파크 데이터 타입 : 자체 데이터 타입 정보를 가지고 있는 카탈리스트 엔진 사용

* 각 언어별 매핑 테이블 존재

- Row : 데이터 레코드. 스파크가 사용하는 연산에 최적화된 인메모리 포맷의 내부적인 표현 방식

* GC와 객체 초기화 부하가 있는 JVM 데이터 타입 대신, 자체 데이터 포맷 사용 가능

- Column : 단순 데이터 타입, 복합 데이터 타입, null 값을 표현

- 구조적 API 실행 과정

1) 코드 작성 by 개발자

2) 논리적 실행 계획 by 스파크

: 추상적 tr만 표현

2-1) 검증 by 분석기: 표현식을 최적화된 버전으로 변환, 코드 유효성, 테이블/컬럼 존재 유무 판단, 카탈로그, 테이블 저장소, DF 정보 활용

2-2) 최적화 by 카탈리스트 옵티마이저 : 조건절 푸시 다운, 선택절 구문 이용해 최적화. 옵티마이저 확장 가능

3) 최적화하면서 물리적 실행 계획(스파크실행계획)으로 변경 by 스파크

: 비용 모델 생성 -> 비교 -> 최적 : RDD와 tr로 컴파일

4) 물리적 실행 계획 실행(RDD) in Cluster

: 런타임, 전체 테스크나 스테이지를 제거할 수 있는 자바 바이트 코드를 생성 : 추가적인 최적화 수행