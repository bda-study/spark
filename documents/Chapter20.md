# Chapter 20. 스트림 처리의 기초

스파크 스트리밍 API를 알아보기 전에 스트리밍과 배치 처리의 개념을 알아보자

## 스트림 처리란

- 신규 데이터를 끊임없이 처리해 결과를 만들어내는 것
- 무한한 입력 데이터, 시작과 끝을 정의하지 않음
- [연속형 어플리케이션](https://databricks.com/blog/2016/07/28/continuous-applications-evolving-streaming-in-apache-spark-2-0.html)
    - 스트리밍, 배치, 대화형 작업으로 구성된 통합 애플리케이션
- 실전에서 스트림 처리와 배치 처리를 함께 사용하기도 함
    - ex1) 배치 작업의 결과물을 스트리밍 어플리케이션이 조인에서 사용
    - ex2) 스트리밍 작업의 결과물이 배치 작업의 쿼리에서 파일이나 테이블로 사용
    - 즉, 배치와 스트림 처리에 사용되는 코드는 일관성 있게 동작해야함
    - 따라서, 구조적 스트리밍은 배치 등 나머지 컴포넌트와 쉽게 연동 가능하도록 설계됨

### 1. 스트림 처리 사례

#### 1.1 통보와 알림

- 특정 이벤트나 이벤트 패턴을 감지하고 알람 혹은 통보

#### 1.2 실시간 리포트

- 실시간 대시보드를 통한 BI
- 다양한 지표 metric 관찰하기 위해 사용

#### 1.3 증분형 ETL

- 신규 증분 데이터를 수 초 내에 반영
    - ex) 원천 데이터의 증분을 읽어들여 ETL 처리 후 파케이 실시간 저장
- 내고장성을 보장하면서, 정확히 한 번 수행되어야 함. 즉, 중복이나 유실이 없도록 보장되어야 함.
- 트랜잭션을 보장해야 함

#### 1.4 실시간 제공용 데이터 갱신

- 다른 저장소의 동기식 증분 업데이트를 통한 서비스 제공
    - ex) GA가 심어진 페이지에 방문자가 방문하면 view 이벤트가 스트리밍 어플리케이션으로 전달되고, 스트리밍이 GA 어드민의 저장소에 실시간 반영

#### 1.5 실시간 의사결정

- 신규 입력을 분석하고 비즈니스 로직에 따라 실시간 처리
    - ex) 신용카드 고객이 트랜잭션 발생 시 최근 이력을 분석해 부정행위 여부 판단, 의심될 경우 거부
- 대규모 상태 정보를 메모리에 유지

#### 1.6 온라인 머신러닝

- 사용자의 실시간 데이터와 이력을 조합해 머신러닝 모델 학습에 사용
    - ex) 신용카드사의 단일 고객이 아닌 모든 고객의 행동 기반 모델을 갱신 학습하여 각 트랜잭션의 부정행위 여부 판단
- 전수 집계, 고정형 데이터셋 조인, 머신러닝 활용, SLA 등 도전적인 사례

### 2. 스트림 처리의 장점

- 대기 시간이 짧다. 밀리세컨드 단위로 빠르게 응답 가능 ex) 의사결정 지원, 알림 사례
- 마지막 증분 유입 상태를 기억하고 결과를 생성하여 배치작업보다 결과 수정에 효율적

### 3. 스트림 처리의 과제

- 이벤트 시간 기준으로 순서가 뒤섞인 데이터 처리
- 대규모 상태 정보 유지하기
- 높은 데이터 처리량 보장하기
- 장애 상황에서도 정확히 한 번 수행하기
- 부하 불균형과 뒤처진 서버 다루기
- 이벤트에 빠르게 응답하기
- 다른 저장소 시스템의 외부 데이터와 조인하기
- 신규 이벤트 도착 시 출력 싱크의 갱신 방법 결정하기
- 출력 시스템에 데이터 저장 시 트랜잭션 보장하기
- 런타임에 비즈니스 로직 변경하기

## 스트림 처리의 핵심 설계 개념

### 1. 레코드 단위 처리와 선언형 API

- 레코드 단위 처리 API
    - 애플리케이션 내부에서 여러 처리 파이프라인을 연결만 해줌
    - 상태 관리를 직접 구현해야 하는 어려움
    - 기존의 여러 스트리밍 시스템이 채택한 방법
- 선언형 API
    - 애플리케이션에서 '무엇'을 '어떻게' 신규 데이터를 처리할지 지정
    - 맵, 리듀스, 필터와 같은 함수형 API 제공
    - 내부적으로 각 연산자의 데이터 처리량, 연산 상태 정보를 자동으로 추적하고 관리
    - 필요한 경우 장애 지점부터 연산 복구 가능

### 2. 이벤트 시간과 처리 시간

- 이벤트 시간: 원천 발생 시점의 타임스템프를 레코드에 저장
    - 스트리밍 시스템이 늦게 도착한 이벤트를 처리하도록 상태 추척 필요
    - 스트리밍 시스템이 모든 이벤트를 수신했다고 결정짓는 적절한 시기 결졍해야 함
- 처리 시간: 각 레코드가 스트리밍 애플리케이션에 도착한 시점
- 구조적 스트리밍을 포함한 많은 선엉형 시스템은 API에 이벤트 시간 처리를 기본적으로 지원

### 3. 연속형 처리와 마이크로 배치 처리

- 연속형 처리
    - 입력된 레코드 단위 처리 (레코드 입력 -> map 함수 적용 -> reducer 상태 갱신)
    - 전체 입력량이 낮을때 빠르게 반응
    - 레코드 단위 부하가 크다 -> 최대 처리량이 낮음
    - 고정형 연산 토폴로지를 사용하므로 전체 시스템을 중지해야 어플리케이션 변경 가능 -> 부하 분산 문제 발생
- 마이크로 배치 처리
    - 입력된 레코드를 모은 배치 단위 처리
    - 배치 시스템의 촤적화 기법 사용 가능 -> 노드당 높은 처리량 얻을 수 있음
    - 워크로드 변화에 따라 동적으로 부하 분산 기술 적용 가능
    - 배치를 모이기 위한 기본적인 지연 시간이 발생
- 실 사용에서는 지연 시간 요건(즉 sla)과 운영 비용을 절충 고려해야함. 마이크로 배치 + 고속 서빙 계층(MySQL, 카산드라 등)을 사용하는 것도 방법 중 하나

## 스파크의 스트리밍 API

### 1. DStream API

- 2016년도 기준 가장 널리 사용된 스트림 처리 엔진
- 제약사항
    1. DataFrame, Dataset과 달리 자바나 파이썬의 객체, 함수에 매우 의존적이므로 엔진의 다양한 최적화 기법 적용 안됨
    2. 기본적으로 처리 시간 기준으로 동작
    3. 마이크로 배치 형태로만 동작

### 2. 구조적 스트리밍

- 스파크의 구조적 API를 기반으로 하는 고수준 스트리밍 API
- 구조적 데이터 모델을 기반으로 만들어져 다양한 최적화 기술 자동 수행
- 이벤트 시간 데이터 처리 지원
- 스파크 2.3 버전부터 마이크로 배치 뿐만 아니라 연속형 처리 모드 지원 (체험판)
- 스트리밍, 배치, 대화형을 합친 하나의 통합형 어플리케이션으로도 작성 가능하도록 설계됨

## 정리

- 스트리밍 기본 개념과 설계 방법
- 트레이드오프를 고려하여 적합한 시스템 평가
- 구조적 스트리밍이 구조적 데이터 모델을 지원하여 얻는 이점